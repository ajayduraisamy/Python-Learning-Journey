# DL Day 28 â€” FlashAttention (Concept & Implementation)

Includes:
- FlashAttention theory
- Chunked attention implementation
- Performance comparison demo

Run:
python demos/test_flash.py
python demos/compare_attention.py

Note:
This is a conceptual implementation.
Real FlashAttention uses CUDA kernels.
