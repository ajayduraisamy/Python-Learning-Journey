# Advanced Optimizers

### AdamW
Adam + Weight decay (used in Transformers)

### RAdam
Rectified Adam â†’ stable updates

### Lookahead Optimizer
Optimizer that "looks ahead" to stabilize training

### LAMB
Used for training BERT at massive batch sizes
