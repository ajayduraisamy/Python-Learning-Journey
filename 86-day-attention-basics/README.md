# DL Day 15 â€” Scaled Dot-Product Attention (Q/K/V)

### Includes:
- Clean explanation of attention
- Why Q, K, V exist
- Scaled Dot-Product Attention implementation
- Demo script using random tensors
- Toy example for intuitive understanding

### Run demos:
