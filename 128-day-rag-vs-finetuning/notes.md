## Key Learnings – Day 128

- Fine-tuning ≠ knowledge injection
- RAG handles dynamic data best
- Many systems need BOTH
- Retrieval quality matters more than model size
- Always decide based on update frequency & cost
- RAG is a good starting point for new projects
- Fine-tuning is better for high-quality data

## Key Takeaways

- Fine-tuning is a powerful technique for improving the performance of a pre-trained language model by training it on a specific task or dataset. It allows the model to learn task-specific knowledge and adapt to the nuances of the data.
- However, fine-tuning can be computationally expensive and time-consuming, especially for large models and large datasets. It also requires a significant amount of labeled data, which may not always be available or may not be of high quality.