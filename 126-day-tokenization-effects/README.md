# Day 126 – Tokenization Effects in LLMs

LLMs operate on tokens, not characters or words.
Small text changes can cause large token count differences.

Covered:
- What tokenization is
- Why token count ≠ word count
- BPE intuition (subword splits)
- Impact on context window and cost
- Prompt design for token efficiency
